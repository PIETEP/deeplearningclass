{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(YourID)_report2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "TWJdvzABqy4g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Machine Learning: Intermediate report\n",
        "\n",
        "+ Your name (Your ID)"
      ]
    },
    {
      "metadata": {
        "id": "mK2Y44D2qy4i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Prepare an environment for running Python codes on Jupyter notebook. The most easiest way is to use [Google Colaboratory](https://colab.research.google.com/).\n",
        "\n",
        "Write codes for the following three (and one optional) problems, and submit the notebook (`.ipynb`) as well as its HTML conversion (`.html`). *We do not accept a report in other formats (e.g., Word, PDF)*. Write a code at the specified cell in the notebook. One can add more cells if necessary.\n",
        "\n",
        "These are the links to the sample codes used in the lecture:\n",
        "\n",
        "+ [Binary classification](https://github.com/chokkan/deeplearningclass/blob/master/mlp_binary.ipynb)\n",
        "+ [MNIST](https://github.com/chokkan/deeplearningclass/blob/master/mnist.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Kx7KcviKqy4j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Multi-class classification on MNIST\n",
        "\n",
        "Train a model on the training set of MNIST, and report the accuracy of the model on the test set. One can use the same code shown in the lecture. Write a code here and show the output."
      ]
    },
    {
      "metadata": {
        "id": "pzwLueAtqy4j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import os\n",
        "import sys\n",
        "import struct\n",
        "import numpy as np\n",
        "\n",
        "def read_image(fi):\n",
        "  magic, n, rows, columns = struct.unpack(\">IIII\", fi.read(16))\n",
        "  assert magic==0x00000803\n",
        "  assert rows==28\n",
        "  assert columns==28\n",
        "  rawbuffer=fi.read()\n",
        "  assert len(rawbuffer)==n*rows*columns\n",
        "  rawdata=np.frombuffer(rawbuffer,dtype='>u1',count=n*rows*columns)\n",
        "  #dtype>u1:符号なし8ビット整数型を表現　　ビッグエンディアン\n",
        "  #np.frombuffer https://docs.scipy.org/doc/numpy/reference/generated/numpy.frombuffer.html\n",
        "  return rawdata.reshape(n,rows,columns).astype(np.float32)/255.0\n",
        "\n",
        "def read_label(fi):\n",
        "  magic,n=struct.unpack(\">ll\",fi.read(8))\n",
        "  assert magic == 0x00000801\n",
        "  rawbuffer=fi.read()\n",
        "  assert len(rawbuffer)==n\n",
        "  return np.frombuffer(rawbuffer,dtype='>u1',count=n)\n",
        "\n",
        "if __name__=='__main__':\n",
        "  os.system('wget -N http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz')\n",
        "  os.system('wget -N http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz')\n",
        "  os.system('wget -N http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz')\n",
        "  os.system('wget -N http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz')\n",
        "  \n",
        "  np.savez_compressed(\n",
        "        'mnist',\n",
        "        train_x=read_image(gzip.open('train-images-idx3-ubyte.gz', 'rb')),\n",
        "        train_y=read_label(gzip.open('train-labels-idx1-ubyte.gz', 'rb')),\n",
        "        test_x=read_image(gzip.open('t10k-images-idx3-ubyte.gz', 'rb')),\n",
        "        test_y=read_label(gzip.open('t10k-labels-idx1-ubyte.gz', 'rb'))\n",
        "    )\n",
        "  #https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.savez_compressed.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7CREwXBVVP5Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data=np.load('mnist.npz')\n",
        "\n",
        "print(data['train_x'].shape, data['train_x'].dtype)\n",
        "print(data['train_y'].shape, data['train_y'].dtype)\n",
        "print(data['test_x'].shape, data['test_x'].dtype)\n",
        "print(data['test_y'].shape, data['test_y'].dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TzE0rr6pVrTl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "#Index number of an instance (change this to view another instance)\n",
        "i=0\n",
        "\n",
        "data=np.load('mnist.npz')\n",
        "image=data['train_x'][i]\n",
        "label=data['train_y'][i]\n",
        "\n",
        "print(label)\n",
        "f,ax=plt.subplots(figsize=(16,16))\n",
        "#https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html\n",
        "sns.heatmap(image,annot=True,fmt='.1f',square=True,cmap=\"YlGnBu\")\n",
        "#https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
        "#annot:Trueにすると各セルにデータ値を書き込む\n",
        "#fmt:annotの書式,小数点1桁まで\n",
        "#sqaure:Trueにすると各セルを正方形に\n",
        "#cmap対応色:https://matplotlib.org/examples/color/colormaps_reference.html\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OJ7gdmSeb-zO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "5357f164-f6c7-4685-a8f2-bc34a0224a98"
      },
      "cell_type": "code",
      "source": [
        "!pip  install livelossplot"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting livelossplot\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/01/3e34559dbdb98580d5e8f62bc3853975c2a2079834bfba2c1bdffe680804/livelossplot-0.2.0.tar.gz\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from livelossplot) (2.1.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from livelossplot) (5.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.5.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2018.5)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (1.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.2.0)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (1.14.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (2.10)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.5.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.3.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.2.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.3.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.4.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.4.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->livelossplot) (1.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook->livelossplot) (5.5.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook->livelossplot) (4.3.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->livelossplot) (16.0.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (1.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: mistune>=0.7.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.8.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.2.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.3.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->livelossplot) (2.6.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (39.1.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (1.0.15)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.7.4)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (4.6.0)\n",
            "Requirement already satisfied: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->livelossplot) (1.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.1.7)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre->bleach->nbconvert->notebook->livelossplot) (0.5.1)\n",
            "Building wheels for collected packages: livelossplot\n",
            "  Running setup.py bdist_wheel for livelossplot ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/67/8b/e9/3990164e3b2a421145b9d9d76fc8aa889225d495b043faeb73\n",
            "Successfully built livelossplot\n",
            "Installing collected packages: livelossplot\n",
            "Successfully installed livelossplot-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eHdRHmyc6wTC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "c0483d60-76b1-4a18-8b16-511fb6fd273d"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 26kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x590fa000 @  0x7f11120341c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 2.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/24/f53ff6b61b3d728b90934bddb4f03f8ab584a7f49299bf3bde56e2952612/Pillow-5.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 3.6MB/s \n",
            "\u001b[?25hInstalling collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.2.0 torch-0.4.1 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XJS9YZpBcZiN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "439ef17d-2cab-48f3-b958-d91da2892c83"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#CNN\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "import numpy as np\n",
        "from livelossplot import PlotLosses\n",
        "\n",
        "device=torch.device(\"cpu\")\n",
        "#device=torch.device(\"cuda:0\")\n",
        "\n",
        "def create_dataset(x,y):\n",
        "  xt=torch.from_numpy(x).view(len(x),-1)\n",
        "  #from_numpy (x)  x(np.ndarray)からテンソルを生成し、ndarrayとテンソルの反抗を互いに反映させる\n",
        "  yt=torch.from_numpy(y).long()\n",
        "  #self.long() is equivalent to self.to(torch.int64)\n",
        "  return TensorDataset(xt,yt)\n",
        "\n",
        "class Flatten(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Flatten,self).__init__()\n",
        "    \n",
        "  def forward(self,x):\n",
        "    return x.view(-1,512)\n",
        "\n",
        "model=torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(1,16,(5,5)),\n",
        "    #Conv2d(入力の数,出力の数,畳み込みカーネルのサイズ)\n",
        "    torch.nn.MaxPool2d(2),\n",
        "    #MaxPool2d(プーリングのウインドウサイズ)\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Dropout(),\n",
        "    torch.nn.Conv2d(16,32,(5,5)),\n",
        "    torch.nn.MaxPool2d(2),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Dropout(),\n",
        "    Flatten(),\n",
        "    torch.nn.Linear(512,256),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Dropout(),\n",
        "    torch.nn.Linear(256,10),\n",
        "  )\n",
        "print(model)\n",
        "model.to(device)\n",
        "\n",
        "data=np.load('mnist.gpz')\n",
        "train_set=create_dataset(data['train_x'],data['train_y'])\n",
        "test_set=create_dataset(data['test_x'],data['test_y'])\n",
        "train_loader=DataLoader(train_set,batch_size=256,shuffle=True)\n",
        "test_loader=DataLoader(test_set,batch_size=128)\n",
        "\n",
        "loss_fn=nn.CrossEntrropyLoss(size_average=False)\n",
        "#size_average:Falseにすると各ミニバッチの損失が合計される\n",
        "optimizer=optim.SGD(model.parameters(),lr=0.001)\n",
        "\n",
        "liveloss=PlotLosses()\n",
        "for t in rane(100):\n",
        "  train_loss=0\n",
        "  train_correct=0\n",
        "  \n",
        "  #Training loop for mini-batches\n",
        "  for batch_idx,(x,y) in enumerate(train_loader):\n",
        "    #Make predictions with the current parameters\n",
        "    x,y=x.to(device),y.to(device)\n",
        "    y_pred=model(x)\n",
        "    _,predicted=torch.max(y_pred.data,1)\n",
        "    train_correct += (predicted==y).sum().item()\n",
        "    \n",
        "    #Compute the loss value\n",
        "    loss=loss_fn(y_pred,y)\n",
        "    train_loss+=loss.item()\n",
        "    \n",
        "    #Update the parameters\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  #Compute the  average loss ad accuracy\n",
        "  train_loss /= len(train_loader.dataset)\n",
        "  train_correct /= float(len(train_loader.dataset))\n",
        "  \n",
        "  #Evalute the model on the test set\n",
        "  test_loss,test_correct=test_model(model,loss_fn,test_loader,device)\n",
        "  \n",
        "  #Visualize the loss and accuracy values\n",
        "  liveloss.update({\n",
        "      'log loss':train_loss,\n",
        "      'val_log loss':test_loss,\n",
        "      'accuracy':train_correct,\n",
        "      'val_accuracy':test_correct\n",
        "  })\n",
        "  \n",
        "  liveloss.draw()\n",
        "  \n",
        "print('Accuracy: {:.4f}(test),{:.4f}(train)'.format(test_correct,train_correct))\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (2): ReLU()\n",
            "  (3): Dropout(p=0.5)\n",
            "  (4): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (6): ReLU()\n",
            "  (7): Dropout(p=0.5)\n",
            "  (8): Flatten()\n",
            "  (9): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (10): ReLU()\n",
            "  (11): Dropout(p=0.5)\n",
            "  (12): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qALgrytfqy4o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Confusion matrix\n",
        "\n",
        "Show a confusion matrix of the predictions of the model on the test set. This is an example of a confusion matrix.\n",
        "\n",
        "![example](https://github.com/PIETEP/deeplearningclass/blob/master/assignment/example-confusion-matrix.png?raw=1)\n",
        "\n",
        "Write a code here and show the confusion matrix."
      ]
    },
    {
      "metadata": {
        "id": "6egMyZmEqy4o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qtu3s6nzqy4r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Top-3 confusing examples\n",
        "\n",
        "Show the top three images where the model misrecognized their digits with strong confidences. More specifically, let $y_n$ and $\\hat{y}_n$ the true and predicted, respectively, digits of the image $x_n$. We want to find three images with high $P(\\hat{y}_n | x_n)$ when $y_n \\neq \\hat{y}_n$.\n",
        "\n",
        "Please show $y_n$, $P(y_n | x_n)$, $\\hat{y}_n$, and $P(\\hat{y}_n | x_n)$. This is an example of an output for an image (you need this kind of outputs for top-three images).\n",
        "\n",
        "![example](https://github.com/PIETEP/deeplearningclass/blob/master/assignment/example-confusing-sample.png?raw=1)\n",
        "\n",
        "Write a code here and show the output."
      ]
    },
    {
      "metadata": {
        "id": "4PzcO7ogqy4t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ShZbHDKqqy4y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Sample codes in other DL frameworks\n",
        "\n",
        "(Advanced; optional) Implement one or more sample code(s) with a different deep learning framework (e.g., Chainer, TensorFlow, DyNet) corresponding to the slides 60-66 in binary classification. *When subitting an answer to this problem, please agree that some of the submitted codes will be distributed on the Web site to improve this lecture.*"
      ]
    },
    {
      "metadata": {
        "id": "WM2SkBfyqy4z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}